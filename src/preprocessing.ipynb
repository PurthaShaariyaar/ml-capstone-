{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "nba_data = pd.read_csv('nba_data.csv')\n",
    "player_mvp_stats = pd.read_csv('player_mvp_stats.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_mapping = {\n",
    "    'LAL': 'LAL', 'PHO': 'PHO', 'DAL': 'DAL', 'MIA': 'MIA', 'CLE': 'CLE', 'WSB': 'WSB', 'CHI': 'CHI', 'GSW': 'GSW',\n",
    "    'IND': 'IND', 'WAS': 'WAS', 'MIN': 'MIN', 'BOS': 'BOS', 'HOU': 'HOU', 'DEN': 'DEN', 'ORL': 'ORL', 'NOH': 'NOP',\n",
    "    'TOR': 'TOR', 'SAC': 'SAC', 'CHO': 'CHO', 'POR': 'POR', 'DET': 'DET', 'PHI': 'PHI', 'UTA': 'UTA', 'MIL': 'MIL',\n",
    "    'VAN': 'MEM', 'SEA': 'OKC', 'NJN': 'BRK', 'NOK': 'NOP', 'LAC': 'LAC', 'OKC': 'OKC', 'ATL': 'ATL', 'CHA': 'CHO',\n",
    "    'MEM': 'MEM', 'NYK': 'NYK', 'NOP': 'NOP', 'BRK': 'BRK', 'SAS': 'SAS', 'CHH': 'CHO'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_mvp_stats['Tm'] = player_mvp_stats['Tm'].map(team_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.merge(nba_data, player_mvp_stats, left_on='team', right_on='Tm', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>mp</th>\n",
       "      <th>mp.1</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg%</th>\n",
       "      <th>3p</th>\n",
       "      <th>3pa</th>\n",
       "      <th>3p%</th>\n",
       "      <th>ft</th>\n",
       "      <th>...</th>\n",
       "      <th>Pts Max</th>\n",
       "      <th>Share</th>\n",
       "      <th>Team</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W/L%</th>\n",
       "      <th>GB</th>\n",
       "      <th>PS/G</th>\n",
       "      <th>PA/G</th>\n",
       "      <th>SRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-2.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x     mp   mp.1    fg   fga    fg%   3p   3pa  3p%    ft  ...  \\\n",
       "0             0  240.0  240.0  39.0  81.0  0.481  6.0  20.0  0.3  14.0  ...   \n",
       "1             0  240.0  240.0  39.0  81.0  0.481  6.0  20.0  0.3  14.0  ...   \n",
       "2             0  240.0  240.0  39.0  81.0  0.481  6.0  20.0  0.3  14.0  ...   \n",
       "3             0  240.0  240.0  39.0  81.0  0.481  6.0  20.0  0.3  14.0  ...   \n",
       "4             0  240.0  240.0  39.0  81.0  0.481  6.0  20.0  0.3  14.0  ...   \n",
       "\n",
       "   Pts Max  Share           Team   W   L   W/L%    GB  PS/G   PA/G   SRS  \n",
       "0      0.0    0.0  Atlanta Hawks  37  45  0.451  15.0  98.2  100.0 -2.23  \n",
       "1      0.0    0.0  Atlanta Hawks  37  45  0.451  15.0  98.2  100.0 -2.23  \n",
       "2      0.0    0.0  Atlanta Hawks  37  45  0.451  15.0  98.2  100.0 -2.23  \n",
       "3      0.0    0.0  Atlanta Hawks  37  45  0.451  15.0  98.2  100.0 -2.23  \n",
       "4      0.0    0.0  Atlanta Hawks  37  45  0.451  15.0  98.2  100.0 -2.23  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Player   Tm\n",
      "0                 Acie Law  ATL\n",
      "1               Al Horford  ATL\n",
      "2        Jeremy Richardson  ATL\n",
      "3              Joe Johnson  ATL\n",
      "4           Josh Childress  ATL\n",
      "...                    ...  ...\n",
      "8287936    Randolph Morris  NYK\n",
      "8287937    Renaldo Balkman  NYK\n",
      "8287938    Stephon Marbury  NYK\n",
      "8287939    Wilson Chandler  NYK\n",
      "8287940      Zach Randolph  NYK\n",
      "\n",
      "[8287941 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select and display only the 'Player' and 'Tm' columns\n",
    "player_and_team_data = combined_data[['Player', 'Tm']]\n",
    "print(player_and_team_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        team team_opp\n",
      "0        ATL      DAL\n",
      "1        ATL      DAL\n",
      "2        ATL      DAL\n",
      "3        ATL      DAL\n",
      "4        ATL      DAL\n",
      "...      ...      ...\n",
      "8287936  NYK      MIL\n",
      "8287937  NYK      MIL\n",
      "8287938  NYK      MIL\n",
      "8287939  NYK      MIL\n",
      "8287940  NYK      MIL\n",
      "\n",
      "[8287941 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select and display only the 'team' and 'team_opp' columns\n",
    "team_and_team_opp_data = combined_data[['team', 'team_opp']]\n",
    "print(team_and_team_opp_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acie Law' 'Al Horford' 'Jeremy Richardson' ... 'Stuart Gray'\n",
      " 'Maurice Ndour' 'Mindaugas Kuzminskas']\n"
     ]
    }
   ],
   "source": [
    "# Get all player names\n",
    "\n",
    "unique_players = combined_data['Player'].unique()\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(unique_players)\n",
    "\n",
    "pd.reset_option('display.max_rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample mapping of player names to their corresponding weights\n",
    "player_weights = {\n",
    "    'Nikola Jokic': 0.98,\n",
    "    'Joel Embiid': 0.97,\n",
    "    'Stephen Curry': 0.97,\n",
    "    'Luka Doncic': 0.96,\n",
    "    'Giannis Antetokounmpo': 0.96,\n",
    "    'LeBron James': 0.96,\n",
    "    'Kevin Durant': 0.96,\n",
    "    'Jayson Tatum': 0.95,\n",
    "    'Devin Booker': 0.94,\n",
    "    'Jimmy Butler': 0.94,\n",
    "    'Donovan Mitchell': 0.93,\n",
    "    'Damian Lillard': 0.93,\n",
    "    'Anthony Davis': 0.93,\n",
    "    'Shai Gilgeous-Alexander': 0.93,\n",
    "    'Kawhi Leonard': 0.92,\n",
    "    'Ja Morant': 0.92,\n",
    "    'Anthony Edwards': 0.90,\n",
    "    'Tyrese Haliburton': 0.90,\n",
    "    'Zion Williamson': 0.89,\n",
    "    'James Harden': 0.89,\n",
    "    'Kyrie Irving': 0.89,\n",
    "    'Paul George': 0.89,\n",
    "    'Jaylen Brown': 0.89,\n",
    "    'Trae Young': 0.88,\n",
    "    'Jamal Murray': 0.88,\n",
    "    'Jalen Brunson': 0.88,\n",
    "    'De’Aaron Fox': 0.88,\n",
    "    'Bam Adebayo': 0.87,\n",
    "    'Tyrese Maxey': 0.87,\n",
    "    'Kristaps Porzingis': 0.87,\n",
    "    'Victor Wembanyama': 0.86,\n",
    "    'Scottie Barnes': 0.86,\n",
    "    'Bradley Beal': 0.86,\n",
    "    'Dejounte Murray': 0.86,\n",
    "    'Jaren Jackson Jr.': 0.86,\n",
    "    'Domantas Sabonis': 0.86,\n",
    "    'Lauri Markkanen': 0.86,\n",
    "    'Jrue Holiday': 0.86,\n",
    "    'Mikal Bridges': 0.86,\n",
    "    'Evan Mobley': 0.85,\n",
    "    'Cade Cunningham': 0.85,\n",
    "    'LaMelo Ball': 0.85,\n",
    "    'Darius Garland': 0.85,\n",
    "    'Karl-Anthony Towns': 0.85,\n",
    "    'DeMar DeRozan': 0.85,\n",
    "    'Pascal Siakam': 0.85,\n",
    "    'Tyler Herro': 0.85,\n",
    "    'C.J. McCollum': 0.85,\n",
    "    'Khris Middleton': 0.85,\n",
    "    'Desmond Bane': 0.85,\n",
    "    'Paolo Banchero': 0.84,\n",
    "    'Rudy Gobert': 0.84,\n",
    "    'Zach LaVine': 0.84,\n",
    "    'Brandon Ingram': 0.84,\n",
    "    'Aaron Gordon': 0.84,\n",
    "    'Nicolas Claxton': 0.84,\n",
    "    'Kyle Kuzma': 0.84,\n",
    "    'Alperen Sengun': 0.84,\n",
    "    'Klay Thompson': 0.83,\n",
    "    'Chet Holmgren': 0.83,\n",
    "    'Draymond Green': 0.83,\n",
    "    'R.J. Barrett': 0.83,\n",
    "    'Jarrett Allen': 0.83,\n",
    "    'Michael Porter Jr.': 0.83,\n",
    "    'Julius Randle': 0.83,\n",
    "    'Anfernee Simons': 0.83,\n",
    "    'Jalen Duren': 0.83,\n",
    "    'Derrick White': 0.83,\n",
    "    'Malcolm Brogdon': 0.83,\n",
    "    'Myles Turner': 0.83,\n",
    "    'Chris Paul': 0.82,\n",
    "    'Jalen Green': 0.82,\n",
    "    'Shaedon Sharpe': 0.82,\n",
    "    'Ausar Thompson': 0.82,\n",
    "    'Deandre Ayton': 0.82,\n",
    "    'Franz Wagner': 0.82,\n",
    "    'OG Anunoby': 0.82,\n",
    "    'Fred VanVleet': 0.82,\n",
    "    'Jonas Valanciunas': 0.82,\n",
    "    'Nikola Vucevic': 0.82,\n",
    "    'Tobias Harris': 0.82,\n",
    "    'Jalen Williams': 0.82,\n",
    "    'Marcus Smart': 0.82,\n",
    "    'Malik Monk': 0.82,\n",
    "    'Brook Lopez': 0.82,\n",
    "    'Bobby Portis': 0.82,\n",
    "    'Mitchell Robinson': 0.82,\n",
    "    'Cam Thomas': 0.82,\n",
    "    'Devin Vassell': 0.82,\n",
    "    'Bojan Bogdanovic': 0.82,\n",
    "    'Austin Reaves': 0.82,\n",
    "    'Josh Giddey': 0.81,\n",
    "    'Lonzo Ball': 0.81,\n",
    "    'Jordan Poole': 0.81,\n",
    "    'Russell Westbrook': 0.81,\n",
    "    'Robert Williams III': 0.81,\n",
    "    'Clint Capela': 0.81,\n",
    "    'John Collins': 0.81,\n",
    "    'Jerami Grant': 0.81,\n",
    "    'Onyeka Okongwu': 0.81\n",
    "}\n",
    "\n",
    "# Add player weights to combined_data\n",
    "combined_data['player_weight'] = combined_data['Player'].map(player_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Player  player_weight\n",
      "0                 Acie Law            0.5\n",
      "1               Al Horford            0.5\n",
      "2        Jeremy Richardson            0.5\n",
      "3              Joe Johnson            0.5\n",
      "4           Josh Childress            0.5\n",
      "...                    ...            ...\n",
      "8287936    Randolph Morris            0.5\n",
      "8287937    Renaldo Balkman            0.5\n",
      "8287938    Stephon Marbury            0.5\n",
      "8287939    Wilson Chandler            0.5\n",
      "8287940      Zach Randolph            0.5\n",
      "\n",
      "[8287941 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "default_weight = 0.5\n",
    "\n",
    "combined_data['player_weight'] = combined_data['Player'].map(player_weights).fillna(default_weight)\n",
    "\n",
    "print(combined_data[['Player', 'player_weight']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n",
      "0.97\n"
     ]
    }
   ],
   "source": [
    "lebron_weight = combined_data.loc[combined_data['Player'] == 'LeBron James', 'player_weight'].values[0]\n",
    "steph_weight = combined_data.loc[combined_data['Player'] == 'Stephen Curry', 'player_weight'].values[0]\n",
    "\n",
    "print(lebron_weight)\n",
    "print(steph_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0_x     mp   mp.1    fg   fga    fg%   3p   3pa  3p%    ft  ...  \\\n",
      "0             0  240.0  240.0  39.0  81.0  0.481  6.0  20.0  0.3  14.0  ...   \n",
      "1             0  240.0  240.0  39.0  81.0  0.481  6.0  20.0  0.3  14.0  ...   \n",
      "2             0  240.0  240.0  39.0  81.0  0.481  6.0  20.0  0.3  14.0  ...   \n",
      "3             0  240.0  240.0  39.0  81.0  0.481  6.0  20.0  0.3  14.0  ...   \n",
      "4             0  240.0  240.0  39.0  81.0  0.481  6.0  20.0  0.3  14.0  ...   \n",
      "\n",
      "   Share           Team   W   L   W/L%    GB  PS/G   PA/G   SRS  player_weight  \n",
      "0    0.0  Atlanta Hawks  37  45  0.451  15.0  98.2  100.0 -2.23            0.5  \n",
      "1    0.0  Atlanta Hawks  37  45  0.451  15.0  98.2  100.0 -2.23            0.5  \n",
      "2    0.0  Atlanta Hawks  37  45  0.451  15.0  98.2  100.0 -2.23            0.5  \n",
      "3    0.0  Atlanta Hawks  37  45  0.451  15.0  98.2  100.0 -2.23            0.5  \n",
      "4    0.0  Atlanta Hawks  37  45  0.451  15.0  98.2  100.0 -2.23            0.5  \n",
      "\n",
      "[5 rows x 194 columns]\n"
     ]
    }
   ],
   "source": [
    "team_weights = {\n",
    "  'pts': 0.833,\n",
    "  'fg%_max': 1.0,\n",
    "  '3p%_max': 0.667,\n",
    "  'ft%_max': 0.417,\n",
    "  'trb_max': 1.0,\n",
    "  'ast_max': 0.917,\n",
    "  'stl_max': 0.75,\n",
    "  'blk_max': 0.75\n",
    "}\n",
    "\n",
    "\n",
    "for col, weight in team_weights.items():\n",
    "  combined_data[col] = combined_data[col] * weight\n",
    "\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           True\n",
      "1           True\n",
      "2           True\n",
      "3           True\n",
      "4           True\n",
      "           ...  \n",
      "8287936    False\n",
      "8287937    False\n",
      "8287938    False\n",
      "8287939    False\n",
      "8287940    False\n",
      "Name: won, Length: 8287941, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['won'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['won'] = combined_data['won'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1\n",
      "1          1\n",
      "2          1\n",
      "3          1\n",
      "4          1\n",
      "          ..\n",
      "8287936    0\n",
      "8287937    0\n",
      "8287938    0\n",
      "8287939    0\n",
      "8287940    0\n",
      "Name: won, Length: 8287941, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['won'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1\n",
      "1          1\n",
      "2          1\n",
      "3          1\n",
      "4          1\n",
      "          ..\n",
      "8287936    0\n",
      "8287937    0\n",
      "8287938    0\n",
      "8287939    0\n",
      "8287940    0\n",
      "Name: won, Length: 8287941, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['won'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Feedforward Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 18:18:00.519614: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]                  0         []                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  1280      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 64)                   8256      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 64)                   0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 32)                   2080      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 33)                   0         ['dense_2[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    34        ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11650 (45.51 KB)\n",
      "Trainable params: 11650 (45.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "207199/207199 [==============================] - 329s 2ms/step - loss: 0.5251 - accuracy: 0.7362 - val_loss: 0.4923 - val_accuracy: 0.7696\n",
      "Epoch 2/10\n",
      "207199/207199 [==============================] - 333s 2ms/step - loss: 0.5070 - accuracy: 0.7509 - val_loss: 0.4727 - val_accuracy: 0.7815\n",
      "Epoch 3/10\n",
      "207199/207199 [==============================] - 324s 2ms/step - loss: 0.5001 - accuracy: 0.7560 - val_loss: 0.4669 - val_accuracy: 0.7897\n",
      "Epoch 4/10\n",
      "207199/207199 [==============================] - 323s 2ms/step - loss: 0.4962 - accuracy: 0.7589 - val_loss: 0.4564 - val_accuracy: 0.7914\n",
      "Epoch 5/10\n",
      "207199/207199 [==============================] - 323s 2ms/step - loss: 0.4936 - accuracy: 0.7609 - val_loss: 0.4529 - val_accuracy: 0.7954\n",
      "Epoch 6/10\n",
      "207199/207199 [==============================] - 322s 2ms/step - loss: 0.4917 - accuracy: 0.7618 - val_loss: 0.4525 - val_accuracy: 0.7983\n",
      "Epoch 7/10\n",
      "207199/207199 [==============================] - 322s 2ms/step - loss: 0.4903 - accuracy: 0.7629 - val_loss: 0.4472 - val_accuracy: 0.8042\n",
      "Epoch 8/10\n",
      "207199/207199 [==============================] - 322s 2ms/step - loss: 0.4889 - accuracy: 0.7637 - val_loss: 0.4406 - val_accuracy: 0.8025\n",
      "Epoch 9/10\n",
      "207199/207199 [==============================] - 322s 2ms/step - loss: 0.4880 - accuracy: 0.7644 - val_loss: 0.4431 - val_accuracy: 0.8036\n",
      "Epoch 10/10\n",
      "207199/207199 [==============================] - 323s 2ms/step - loss: 0.4871 - accuracy: 0.7652 - val_loss: 0.4396 - val_accuracy: 0.8025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x132d47b10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract features and target variable\n",
    "X = combined_data[['pts', 'fg%_max', '3p%_max', 'ft%_max', 'trb_max', 'ast_max', 'stl_max', 'blk_max', 'player_weight']]\n",
    "y = combined_data['won']  # Use the 'won' column as the target variable\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data preprocessing\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Scale the features\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model architecture using the Functional API\n",
    "num_features = X_train_scaled.shape[1]\n",
    "\n",
    "input_layer = tf.keras.layers.Input(shape=(num_features,))\n",
    "hidden1 = tf.keras.layers.Dense(128, activation='relu')(input_layer)\n",
    "dropout1 = tf.keras.layers.Dropout(0.3)(hidden1)\n",
    "hidden2 = tf.keras.layers.Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = tf.keras.layers.Dropout(0.3)(hidden2)\n",
    "hidden3 = tf.keras.layers.Dense(32, activation='relu')(dropout2)\n",
    "player_weight_input = tf.keras.layers.Input(shape=(1,))\n",
    "merged = tf.keras.layers.Concatenate()([hidden3, player_weight_input])\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_layer, player_weight_input], outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit([X_train_scaled, X_train['player_weight']], y_train,\n",
    "          epochs=10, batch_size=32,\n",
    "          validation_data=([X_test_scaled, X_test['player_weight']], y_test))\n",
    "\n",
    "# Prediction\n",
    "# For new predictions, you would preprocess the new data (let's call it new_data) in the same way as X_train\n",
    "# Example:\n",
    "# new_data_scaled = scaler.transform(new_data_features)\n",
    "# predictions = model.predict([new_data_scaled, new_data_player_weight])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 9), found shape=(None, 8)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/purthasmacbookpro/Desktop/ML/ml capstone/src/preprocessing.ipynb Cell 22\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/purthasmacbookpro/Desktop/ML/ml%20capstone/src/preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m team1 \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnter team one: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/purthasmacbookpro/Desktop/ML/ml%20capstone/src/preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m team2 \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnter team two: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/purthasmacbookpro/Desktop/ML/ml%20capstone/src/preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m prediction \u001b[39m=\u001b[39m predict_game_outcome(team1, team2, combined_data, scaler, model)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/purthasmacbookpro/Desktop/ML/ml%20capstone/src/preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mprint\u001b[39m(prediction)\n",
      "\u001b[1;32m/Users/purthasmacbookpro/Desktop/ML/ml capstone/src/preprocessing.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/purthasmacbookpro/Desktop/ML/ml%20capstone/src/preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m main_features_scaled \u001b[39m=\u001b[39m input_features_scaled[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/purthasmacbookpro/Desktop/ML/ml%20capstone/src/preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m player_weights \u001b[39m=\u001b[39m input_features_scaled[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/purthasmacbookpro/Desktop/ML/ml%20capstone/src/preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict([main_features_scaled, player_weights])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/purthasmacbookpro/Desktop/ML/ml%20capstone/src/preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mif\u001b[39;00m predictions[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/purthasmacbookpro/Desktop/ML/ml%20capstone/src/preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mteam1_name\u001b[39m}\u001b[39;00m\u001b[39m is predicted to win against \u001b[39m\u001b[39m{\u001b[39;00mteam2_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/w8/mnscyg917c11hjdybw3887x80000gn/T/__autograph_generated_file4xj1l6yk.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/purthasmacbookpro/miniconda3/envs/test/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 9), found shape=(None, 8)\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve team data\n",
    "def get_team_data(team_name, combined_data):\n",
    "    # Filter the DataFrame for rows matching the team name\n",
    "    team_data_filtered = combined_data[(combined_data['team'] == team_name) | (combined_data['team_opp'] == team_name)]\n",
    "\n",
    "    if team_data_filtered.empty:\n",
    "        raise ValueError(f\"No data found for team: {team_name}\")\n",
    "\n",
    "    numeric_columns = ['pts', 'fg%_max', '3p%_max', 'ft%_max', 'trb_max', 'ast_max', 'stl_max', 'blk_max', 'player_weight']\n",
    "    team_data_numeric = team_data_filtered[numeric_columns]\n",
    "    team_data_mean = team_data_numeric.mean()\n",
    "    average_player_weight = combined_data[combined_data['Tm'] == team_name]['player_weight'].mean()\n",
    "    return team_data_mean, average_player_weight\n",
    "\n",
    "# Function to predict game outcome\n",
    "def predict_game_outcome(team1_name, team2_name, combined_data, scaler, model):\n",
    "    team1_data, team1_player_weight = get_team_data(team1_name, combined_data)\n",
    "    team2_data, team2_player_weight = get_team_data(team2_name, combined_data)\n",
    "\n",
    "    features_team1 = [team1_data['pts'], team1_data['fg%_max'], team1_data['3p%_max'],\n",
    "                      team1_data['ft%_max'], team1_data['trb_max'], team1_data['ast_max'],\n",
    "                      team1_data['stl_max'], team1_data['blk_max'], team1_player_weight]\n",
    "\n",
    "    features_team2 = [team2_data['pts'], team2_data['fg%_max'], team2_data['3p%_max'],\n",
    "                      team2_data['ft%_max'], team2_data['trb_max'], team2_data['ast_max'],\n",
    "                      team2_data['stl_max'], team2_data['blk_max'], team2_player_weight]\n",
    "\n",
    "    input_features = np.array([features_team1, features_team2])\n",
    "    input_features_scaled = scaler.transform(input_features)\n",
    "\n",
    "    predictions = model.predict(input_features_scaled)\n",
    "\n",
    "    # Interpret the prediction for team 1\n",
    "    if predictions[0] > 0.5:\n",
    "        return f\"{team1_name} is predicted to win against {team2_name}\"\n",
    "    else:\n",
    "        return f\"{team2_name} is predicted to win against {team1_name}\"\n",
    "\n",
    "\n",
    "# User interaction and prediction call\n",
    "team1 = input(\"Enter team one: \")\n",
    "team2 = input(\"Enter team two: \")\n",
    "prediction = predict_game_outcome(team1, team2, combined_data, scaler, model)\n",
    "print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
